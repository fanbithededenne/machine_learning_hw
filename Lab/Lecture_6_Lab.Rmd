---
title: "Machine Learning in Public Health"
author: "Dr. Yang Feng"
subtitle: 'Lecture 6: Linear Model Selection and Regularization (Lab)'
output:
  html_document: 
    df_print: paged
    number_sections: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE,
                      warnings = FALSE, fig.align = 'center',  eval = TRUE)
```


# Best Subset Selection 


```{r}
library(ISLR)
library(tidyverse)
data("Credit")
credit_cate <- Credit %>% select(-ID)
credit <- model.matrix( ~ . , data = credit_cate) %>% 
  as_tibble() %>% 
  select(-"(Intercept)") 
set.seed(0)
tr_ind <- sample(1:nrow(credit), 200)
credit_tr <- credit[tr_ind, ]
credit_te <- credit[-tr_ind, ]
``` 

```{r}
library(leaps)
best_subset <- regsubsets(Balance ~ ., data = credit_tr) ##default only considers models size up to 8
#summary(best_subset)
best_subset <- regsubsets(Balance ~ ., data = credit_tr, nvmax = 11) ##now considers all 11 variables

best_subset_sum <- summary(best_subset)
best_subset_sum$rsq
#par(mfrow = c(2,2))
plot(best_subset, scale = "r2")
plot(best_subset, scale = "adjr2")
plot(best_subset, scale = "Cp")
plot(best_subset, scale = "bic")
```

## Optimal model for each size: four methods

```{r}
measures <- c("rsq", "adjr2", "cp", "bic")
our_names <- c("R2", "Adjusted R2", "Cp", "BIC")
size_seq <- 1:length(best_subset_sum$rsq)
my_plots <- NULL
for(mea_ind in seq_along(measures)){
  dat <- data.frame(d = size_seq, val = best_subset_sum[[measures[mea_ind]]])
  my_plots[[mea_ind]] <- ggplot(dat, mapping = aes(x = d, y = val)) + geom_point() + geom_line() +
    ggtitle(our_names[mea_ind])
}
library(egg)
grid.arrange(grobs = my_plots, ncol = 2)
```

## Coefficients corresponding to optimal models
```{r, echo = TRUE}
coef(best_subset, 1:11)
coef(best_subset, 4)
```

```{r}
best_ind <- which.min(best_subset_sum$bic) #best index using bic
best_coef <- coef(best_subset, best_ind)
tr_x <- credit_tr %>% select(names(best_coef)[-1])
tr_pred <- cbind(1, as.matrix(tr_x)) %*% best_coef
tr_error <- mean((tr_pred - credit_tr$Balance)^2)
te_x <- credit_te %>% select(names(best_coef)[-1])
te_pred <- cbind(1, as.matrix(te_x)) %*% best_coef
te_error <- mean((te_pred - credit_te$Balance)^2)

tr_error
te_error
```


# Forward Stepwise Selection 

```{r}
forward_fit <- regsubsets(Balance ~ ., data = credit_tr, method = "forward", nvmax = 11)
forward_sum <- summary(forward_fit)
best_ind <- which.min(forward_sum$bic)
coef(forward_fit, best_ind)
```


```{r}
best_ind <- which.min(forward_sum$bic) #best index using bic
best_coef <- coef(forward_fit, best_ind)
tr_x <- credit_tr %>% select(names(best_coef)[-1])
tr_pred <- cbind(1, as.matrix(tr_x)) %*% best_coef
tr_error <- mean((tr_pred - credit_tr$Balance)^2)
te_x <- credit_te %>% select(names(best_coef)[-1])
te_pred <- cbind(1, as.matrix(te_x)) %*% best_coef
te_error <- mean((te_pred - credit_te$Balance)^2)
tr_error
te_error
```

## Optimal model for each size: four methods

```{r}
size_seq <- 1:length(forward_sum$rsq)
my_plots <- NULL
for(mea_ind in seq_along(measures)){
  dat <- data.frame(d = size_seq, val = forward_sum[[measures[mea_ind]]])
  my_plots[[mea_ind]] <- ggplot(dat, mapping = aes(x = d, y = val)) + geom_point() + geom_line() +
    ggtitle(our_names[mea_ind])
}
grid.arrange(grobs = my_plots, ncol = 2)
```

# Backward Stepwise Selection 


```{r}
backward_fit <- regsubsets(Balance ~ ., data = credit_tr, method = "backward", nvmax = 11)
backward_sum <- summary(backward_fit)
best_ind <- which.min(backward_sum$bic)
coef(backward_fit, best_ind)
```

```{r}
best_ind <- which.min(backward_sum$bic) #best index using bic
best_coef <- coef(backward_fit, best_ind)
tr_x <- credit_tr %>% select(names(best_coef)[-1])
tr_pred <- cbind(1, as.matrix(tr_x)) %*% best_coef
tr_error <- mean((tr_pred - credit_tr$Balance)^2)
te_x <- credit_te %>% select(names(best_coef)[-1])
te_pred <- cbind(1, as.matrix(te_x)) %*% best_coef
te_error <- mean((te_pred - credit_te$Balance)^2)
tr_error
te_error
```


## Optimal model for each size: four methods

```{r}
size_seq <- 1:length(backward_sum$rsq)
my_plots <- NULL
for(mea_ind in seq_along(measures)){
  dat <- data.frame(d = size_seq, val = backward_sum[[measures[mea_ind]]])
  my_plots[[mea_ind]] <- ggplot(dat, mapping = aes(x = d, y = val)) + geom_point() + geom_line() +
    ggtitle(our_names[mea_ind])
}
grid.arrange(grobs = my_plots, ncol = 2)
```





# Ridge solution path for Credit data

```{r}
library(glmnet)
library(caret)
x_tr <- as.matrix(credit_tr[, -12])
y_tr <- credit_tr[, 12, drop = T]
x_te <- as.matrix(credit_te[, -12])
y_te <- credit_te[, 12, drop = T]
std_fit <- preProcess(x_tr, method = c("center", "scale"))
x_tr_std <- predict(std_fit, x_tr)
x_te_std <- predict(std_fit, x_te)
fit_ridge <- glmnet(x_tr_std, y_tr, alpha = 0)
library(plotmo)
plot_glmnet(fit_ridge)
```



```{r}
cv_fit_ridge <- cv.glmnet(x_tr, y_tr, alpha = 0)
tr_pred <- predict(cv_fit_ridge, newx = x_tr)
te_pred <- predict(cv_fit_ridge, newx = x_te)
tr_error <- mean((tr_pred - y_tr)^2)
te_error <- mean((te_pred - y_te)^2)
tr_error
te_error

cv1 <- cv.glmnet(x_tr,y_tr,alpha = 0)
cv2 <- cv.glmnet(x_tr_std,y_tr,alpha = 0)
cv3 <- cv.glmnet(scale(x_tr,center = T),y_tr,alpha = 0)

p1 <- predict(cv1, newx = x_te)
p2 <- predict(cv2, newx = x_te_std)
p3 <- predict(cv3, newx = scale(x_te,center = T))

mean((p1-y_te)^2)
mean((p2-y_te)^2)
mean((p3-y_te)^2)

```

# lasso Solution Path 

```{r}
fit_lasso <- glmnet(x_tr_std, y_tr)
plot_glmnet(fit_lasso)
```

```{r}
cv_fit_lasso <- cv.glmnet(x_tr, y_tr)
tr_pred <- predict(cv_fit_lasso, newx = x_tr)
te_pred <- predict(cv_fit_lasso, newx = x_te)
tr_error <- mean((tr_pred - y_tr)^2)
te_error <- mean((te_pred - y_te)^2)
tr_error
te_error
```





